---
title: "알고리즘 핵심: 시간 복잡도 유도 과정 완벽 정복 (분할 정복, 그리디, DP)"
categories: algorithm
tags: [algorithm, time-complexity, divide-and-conquer, greedy, dynamic-programming]
toc: true
toc_sticky: true
author_profile: false
use_math: true
thumbnail : ![alt text](https://upload.wikimedia.org/wikipedia/commons/3/31/1983_CPA_5426.jpg)
---

## Chapter 3: 분할 정복 알고리즘 (Divide and Conquer Algorithm) 

분할 정복은 큰 문제를 해결하기 쉬운 작은 문제로 나눈 뒤, 작은 문제들의 답을 합쳐 원래 문제의 답을 찾는 강력한 문제 해결 전략입니다. 이 챕터에서는 분할 정복의 대표적인 예시들을 다룹니다.

* 3.1 합병 정렬 (Merge Sort)
* 3.2 퀵 정렬 (Quick Sort)
* 3.3 선택 문제 (Selection Problem)
* 3.4 최근접 점의 쌍 찾기 (Closest Pair of Points)
* 3.5 분할 정복을 적용하는 데 있어서 주의할 점

---
## 3.1 합병 정렬 (Merge Sort)
합병 정렬은 전형적인 분할 정복 알고리즘입니다. 큰 문제를 작은 문제로 나누고, 해결된 작은 문제들을 다시 합치면서 최종 해를 구합니다.
---


### 1. 실습 과정 및 의사코드 연관 설명
합병 정렬은 <b>'일단 나누고, 합치면서 정렬한다'</b>는 아이디어를 따릅니다. 강의 자료 13페이지의 A = [37, 10, 22, 30, 35, 13, 25, 24] 예제를 통해 과정을 살펴보겠습니다.

```pseudocode
MergeSort(A, p, q)
    // 입력: A[p]~A[q]
    // 출력: 정렬된 A[p]~A[q]
    if (p < q) { // 배열 원소가 2개 이상일 때만 분할
        k = floor((p+q)/2)      // 1. 분할(Divide): 중간 지점 계산
        MergeSort(A, p, k)      // 2. 정복(Conquer): 왼쪽 부분 재귀 호출
        MergeSort(A, k+1, q)    // 2. 정복(Conquer): 오른쪽 부분 재귀 호출
        Merge(A, p, k, q)       // 3. 결합(Combine): 정렬된 두 부분을 합병
    }
```





### 분할 (Divide) 과정 (라인 2-4)

MergeSort(A, 0, 7)가 호출되면, if (0 < 7)이 참이므로 k=3으로 계산됩니다.

MergeSort(A, 0, 3) (왼쪽)과 MergeSort(A, 4, 7) (오른쪽)이 차례로 호출됩니다.

MergeSort(A, 0, 3)은 다시 [37, 10]과 [22, 30]으로, 최종적으로는 [37], [10], [22], [30]과 같이 원소가 하나만 남을 때까지 재귀적으로 분할됩니다. 이 과정이 강의 자료 그림의 화살표 ①, ②, ③, ④에 해당합니다.

정복 및 합병 (Conquer & Combine) 과정 (라인 5)

재귀 호출이 가장 깊은 곳까지 도달하면 (원소가 1개인 배열), if (p < q) 조건이 거짓이 되어 반환되기 시작합니다.


[37]과 [10]이 Merge 함수의 입력으로 들어가 정렬된 배열 [10, 37]을 만듭니다 (그림의 화살표 ⑤).



마찬가지로 [22]와 [30]이 합병되어 [22, 30]이 됩니다 (그림의 화살표 ⑨).


이렇게 생성된 두 부분 해 [10, 37]과 [22, 30]이 다시 합병되어 [10, 22, 30, 37]이라는 더 큰 부분 해를 만듭니다 (그림의 화살표 ⑩).


이 과정이 전체 배열에 대해 반복되어 최종적으로 정렬된 배열을 얻습니다.

---

### 2. 시간 복잡도 유도 <br>
합병 정렬의 시간 복잡도는 **분할의 깊이(층수)**와 각 층에서 수행되는 합병 연산의 양으로 결정됩니다.

<br>
각 층의 합병 연산: 강의 자료 15페이지의 그림을 보면, 각 층(level)에서 합병되는 원소의 총 개수는 항상 n개입니다. 크기가 m과 n인 두 배열을 합병하는 데는 $O(m+n)$ 시간이 걸리므로, 각 층의 전체 합병 연산 시간은 <b>$O(n)$</b>입니다.
 
분할의 깊이 (층수): 크기 $n$의 배열을 원소 개수가 1이 될 때까지 계속 2로 나누면, 분할의 깊이는 $k$가 되고, 수식으로는 $n/2^k = 1$이 됩니다. 이를 $k$에 대해 풀면 $k = \log_2 n$이 됩니다. 따라서 총 층수는 <b>$O(\log n)$</b>입니다.

결론적으로, 총 시간 복잡도는 (각 층의 시간 복잡도) × (총 층수)이므로, <b>$O(n) \times O(\log n) = O(n \log n)$</b>이 됩니다. 이는 최선, 평균, 최악의 경우 모두 동일합니다.

## 3.2 퀵 정렬 (Quick Sort)
퀵 정렬은 피봇(pivot)을 기준으로 문제를 분할하고, 각 부분 문제를 재귀적으로 해결하는 방식입니다. 합병 정렬과 달리 분할 과정에서 대부분의 작업(정복)이 이루어집니다.
---

### 1. 실습 과정 및 의사코드 연관 설명

A = [6, 3, 11, 9, 12, 2, 8, 15, 18, 10, 7, 14] 예제에서 첫 피봇을 8로 설정하는 과정을 보겠습니다.

```pseudocode
QuickSort(A, left, right)
    if (left < right) {
        p = Partition(A, left, right) // 1. 정복(Conquer): 피봇 기준으로 분할하고 위치 p 반환
        QuickSort(A, left, p-1)       // 2. 분할(Divide): 왼쪽 부분 재귀 호출
        QuickSort(A, p+1, right)      // 2. 분할(Divide): 오른쪽 부분 재귀 호출
    }
```




정복 (Partition) 과정 (라인 2)

피봇(8)을 기준으로 피봇보다 작은 값은 왼쪽, 큰 값은 오른쪽으로 재배치합니다.

강의 자료 24-25페이지의 과정을 보면, i는 왼쪽에서 오른쪽으로, j는 오른쪽에서 왼쪽으로 이동하며 값을 비교하고 교환(swap)합니다.


이 과정이 끝나면 피봇(8)이 자신의 최종 위치(인덱스 4)에 자리 잡고, 배열은 [2, 3, 7, 6], 8, [12, 9, 15, 18, 10, 11, 14]로 분할됩니다. 이 분할 과정 자체가 '정복'에 해당합니다.

분할 (Divide) 과정 (라인 3-4)

피봇을 제외한 왼쪽 부분 배열 A[0]~A[3]에 대해 QuickSort(A, 0, 3)를 재귀 호출합니다.

피봇을 제외한 오른쪽 부분 배열 A[5]~A[11]에 대해 QuickSort(A, 5, 11)을 재귀 호출합니다.

이 과정은 부분 배열의 크기가 1 이하가 될 때까지 반복됩니다.

---

### 2. 시간 복잡도 유도<br>
최선/평균의 경우: 피봇이 매번 배열을 거의 절반으로 나누는 경우입니다.

<br>
분할(Partition) 시간: $n$개의 원소를 피봇과 비교하므로 <b>$O(n)</b>입니다.

분할 깊이: 배열 크기가 계속 1/2로 줄어들므로 깊이는 <b>$O(\log n)</b>입니다.

따라서 평균 시간 복잡도는 <b>$O(n \log n)</b>입니다.

<br>
최악의 경우: 피봇이 항상 가장 작거나 큰 값으로 선택되어, 배열이 n-1개와 0개로 분할되는 경우입니다.

<br>
분할(Partition) 시간: 여전히 <b>$O(n)</b>입니다.

분할 깊이: 재귀 호출이 $n$번 발생하므로 깊이는 <b>$O(n)$</b>이 됩니다.

총 비교 횟수는 $(n-1) + (n-2) + \dots + 1$ 이 되어, 최악의 시간 복잡도는 <b>$O(n^2)</b>입니다.

## 3.3 선택 문제 (Selection Problem)
선택 문제는 정렬되지 않은 n개의 숫자 중 k번째로 작은 숫자를 찾는 문제입니다. 퀵 정렬의 분할 아이디어를 차용하여 효율적으로 해결할 수 있습니다.
---


### 1. 실습 과정 및 의사코드 연관 설명

A = [6, ..., 14]에서 7번째(k=7) 작은 수를 찾는 과정을 보겠습니다.
```pseudocode
Selection(A, left, right, k)
    // 1. 피봇 p를 기준으로 분할 (Partition)
    p = Partition(A, left, right)
    S = (p-1) - left + 1 // Small group의 크기 계산
    if (k <= S) return Selection(A, left, p-1, k) // 답이 Small group에 있음
    else if (k == S + 1) return A[p] // 피봇이 답임
    else return Selection(A, p+1, right, k-S-1) // 답이 Large group에 있음
```



분할 및 탐색 과정 (라인 1-5)

초기 호출: Selection(A, 0, 11, 7).

피봇 8을 기준으로 분할하면, 피봇의 최종 위치는 p=4가 되고, Small group [2, 3, 7, 6]의 크기는 S = 4가 됩니다.

k=7은 S=4보다 크고, S+1=5와도 다릅니다. 따라서 답은 Large group에 있습니다. else문이 실행됩니다.


Large group [12, 9, 15, 18, 10, 11, 14]에서 k - S - 1 = 7 - 4 - 1 = 2번째 작은 수를 찾기 위해 Selection(A, 5, 11, 2)를 재귀 호출합니다.

이 과정을 반복하면, 한쪽 부분 문제는 완전히 버려지고 탐색 범위가 빠르게 줄어듭니다.

---

### 2. 시간 복잡도 유도
선택 알고리즘은 퀵 정렬과 달리 한쪽 부분 문제에 대해서만 재귀 호출을 수행하므로, 시간 복잡도 점화식은 $T(n) = T(\text{size}) + O(n)$ 형태가 됩니다. 여기서 $O(n)$은 분할(Partition)에 걸리는 시간이며, `size`는 다음 탐색 대상이 될 부분 문제의 크기입니다.

<br>
#### 평균 시간 복잡도 (Average Case)
피봇이 랜덤하게 선택될 때, 평균적으로 탐색 대상이 되는 부분 문제의 크기는 약 $\frac{3}{4}n$으로 줄어든다고 가정할 수 있습니다.

*   **분할 비용**: 매 단계에서 $n$개의 원소를 분할하므로 <b>$O(n)$</b>입니다.
*   **재귀 호출**: 문제의 크기가 $n \rightarrow \frac{3}{4}n \rightarrow (\frac{3}{4})^2 n \rightarrow \dots \rightarrow 1$ 과 같이 기하급수적으로 감소합니다.
*   **총비용**: 전체 비용은 등비수열의 합 $T(n) = n + \frac{3}{4}n + (\frac{3}{4})^2 n + \dots$ 으로 표현할 수 있습니다.

이 합은 $n \times \frac{1}{1 - 3/4} = 4n$ 으로 수렴하므로, 평균 시간 복잡도는 <b>$O(n)$</b>입니다.

<br>
#### 최악 시간 복잡도 (Worst Case)
피봇이 계속해서 가장 크거나 작은 값으로 선택되어, 탐색 범위가 매번 1씩만 줄어드는 경우입니다.

*   **분할 비용**: 여전히 <b>$O(n)$</b>입니다.
*   **재귀 호출**: 문제의 크기가 $n \rightarrow n-1 \rightarrow n-2 \rightarrow \dots \rightarrow 1$ 과 같이 1씩 감소합니다.
*   **총비용**: 전체 비용은 $(n) + (n-1) + (n-2) + \dots + 1$ 이 되어, 최악의 시간 복잡도는 <b>$O(n^2)$</b>이 됩니다.

<br>
## 3.4 최근접 점의 쌍 찾기 (Closest Pair of Points)
2차원 평면의 n개 점 중 거리가 가장 가까운 한 쌍의 점을 찾는 문제입니다.
---

### 1. 실습 과정 및 의사코드 연관 설명
이 알고리즘은 점들을 x좌표 기준으로 정렬한 후 분할 정복을 적용합니다.

```pseudocode
ClosestPair(S)
    // 입력: x좌표로 정렬된 점들의 집합 S
    if |S| <= 3: 모든 쌍을 비교하여 최소 거리를 반환
    S를 SL과 SR로 분할
    CPL = ClosestPair(SL) // 왼쪽 부분 문제 해결
    CPR = ClosestPair(SR) // 오른쪽 부분 문제 해결
    d = min(dist(CPL), dist(CPR))
    분할선 L을 기준으로 양쪽으로 d만큼 폭을 가진 '중간 영역(strip)'의 점들을 찾음
    중간 영역 내에서 d보다 가까운 점의 쌍(CPC)이 있는지 확인
    return min(d, dist(CPC))
```
분할 및 재귀 호출 (라인 2-4): 점들을 x좌표의 중앙값을 기준으로 SL과 SR 두 그룹으로 나눕니다. 그리고 각 그룹에 대해 ClosestPair를 재귀적으로 호출하여 각각의 최근접 쌍(CPL, CPR)을 찾습니다.

결합 및 중간 영역 확인 (라인 5-8):


d는 현재까지 발견된 최소 거리입니다.

하지만, 더 가까운 쌍이 한 점은 SL에, 다른 한 점은 SR에 있을 수 있습니다.

이러한 점들은 반드시 분할선으로부터 d 이내의 거리에 있어야 합니다. 이 영역이 바로 '중간 영역(strip)'입니다.

따라서 이 중간 영역에 있는 점들만을 대상으로 추가적인 비교를 수행하여 d보다 더 짧은 거리가 있는지 확인합니다. 이 과정이 정복(Conquer)의 핵심입니다.

---

### 2. 시간 복잡도 유도

<br>
초기 정렬: 모든 점을 x좌표 기준으로 정렬하는 데 $O(n \log n)$ 시간이 걸립니다.

재귀식: $T(n) = 2T(n/2) + (\text{중간 영역 처리 시간})$

중간 영역 처리 시간:
<br>
중간 영역에 속한 점들을 찾는 데는 $O(n)$이 걸립니다.
<br>
이 점들을 y좌표 기준으로 정렬하는 데 $O(n \log n)$이 걸립니다.
<br>
y좌표로 정렬된 후, 각 점에 대해 주변의 상수 개(최대 7개)의 점들과만 거리를 비교하면 되므로 $O(n)$ 시간이 걸립니다.

따라서 한 번의 Combine 단계에서 $O(n \log n)$이 소요됩니다.

전체 시간 복잡도: 재귀식은 $T(n) = 2T(n/2) + O(n \log n)$이 됩니다. 이를 풀면 전체 시간 복잡도는 <b>$O(n \log^2 n)$</b>이 됩니다. (만약 y좌표 정렬을 더 효율적으로 처리하면 <b>$O(n \log n)$</b>까지 줄일 수 있습니다.)


<br><br><br>
## Chapter 4: 그리디 알고리즘 (Greedy Algorithm) 

그리디 알고리즘은 '현재 상황에서 가장 좋아 보이는 것'을 선택하는 방식으로 답을 찾아가는 방법입니다. 항상 최적의 해를 보장하지는 않지만, 특정 문제에서는 매우 빠르고 효율적인 해결책이 될 수 있죠.


* 4.1 동전 거스름돈 (Coin Change)
* 4.2 최소 신장 트리 (Minimum Spanning Tree)
* 4.3 최단 경로 찾기 (Shortest Path)
* 4.4 부분 배낭 문제 (Fractional Knapsack Problem)
* 4.5 집합 커버 문제 (Set Cover Problem)
* 4.6 작업 스케줄링 (Job Scheduling)
* 4.7 허프만 압축 (Huffman Coding)

---
## 4.1 동전 거스름돈 (Coin Change) 
그리디 알고리즘의 가장 직관적인 예시입니다. 거스름돈을 줄 때, 현재 남은 금액을 넘지 않는 가장 큰 액면가의 동전을 '욕심내어' 선택하는 과정을 반복합니다.
---

### 1. 실습 과정 및 의사코드 연관 설명
거스름돈 760원을 500원, 100원, 50원, 10원, 1원 동전으로 거슬러주는 과정입니다. 

```pseudocode
CoinChange(W)
    change = W
    while (change >= 500): change -= 500, n500++
    while (change >= 100): change -= 100, n100++
    while (change >= 50): change -= 50, n50++
    while (change >= 10): change -= 10, n10++
    while (change >= 1): change -= 1, n1++
    return (총 동전 수)
```
초기 상태: change = 760.

500원 동전 선택 (라인 2): 760 >= 500이므로, 500원짜리 1개를 선택합니다. change는 260이 됩니다. 

100원 동전 선택 (라인 3): 260 >= 100이므로, 100원짜리 1개를 선택합니다. change는 160이 됩니다. while 루프가 다시 한번 돌면서 160 >= 100이므로, 100원짜리를 1개 더 선택합니다. change는 60이 됩니다. 

50원 동전 선택 (라인 4): 60 >= 50이므로, 50원짜리 1개를 선택합니다. change는 10이 됩니다. 

10원 동전 선택 (라인 5): 10 >= 10이므로, 10원짜리 1개를 선택합니다. change는 0이 됩니다. 

이후 while 루프들은 조건이 모두 거짓이 되어 종료되고, 총 동전 수(1+2+1+1=5)가 반환됩니다.

---

### 2. 시간 복잡도 유도
이 알고리즘의 복잡도는 거스름돈 액수 W에 비례하는 것처럼 보이지만, 실제로는 각 while 루프가 (W / 동전 액면가) 만큼 반복됩니다.

<br>하지만 동전의 종류(k)는 고정된 상수입니다. 알고리즘의 총 연산 횟수는 W를 모든 동전 액면가로 나누는 연산의 합에 비례합니다.

따라서, 동전 종류가 고정되어 있을 때, 시간 복잡도는 <b>$O(W)$</b>라고 볼 수 있습니다. 하지만 강의 자료의 의사코드는 각 액면가마다 반복적으로 빼기 때문에 정확한 분석은 조금 더 복잡합니다. 더 일반적인 동적 계획법 방식에서는 <b>$O(nk)$</b> ($n$=액수, $k$=동전 종류)가 됩니다.

## 4.2 최소 신장 트리 (Minimum Spanning Tree, MST)
주어진 가중치 그래프에서 모든 정점을 사이클 없이 연결하되, 간선들의 가중치 합이 최소가 되는 트리를 찾는 문제입니다.
---

### 크러스컬 알고리즘 (Kruskal's Algorithm)

#### 1. 실습 과정 및 의사코드 연관 설명
<b>'가장 가중치가 낮은 간선부터, 사이클을 만들지 않는다면 계속해서 추가'</b>하는 전략입니다.

```pseudocode
KruskalMST(G)
    가중치 오름차순으로 간선들을 정렬 (L)
    T = ∅
    while (T의 간선 수 < n-1) {
        L에서 가장 작은 가중치를 가진 간선 e를 가져옴
        if (간선 e가 T에 추가되어 사이클을 만들지 않으면) {
            e를 T에 추가
        } else {
            e를 버린다
        }
    }
    return T
```
강의 자료 16~23페이지의 과정을 봅시다.

초기화 (라인 1-2): 모든 간선을 가중치 순으로 정렬합니다. L = [(b,c,1), (c,f,1), (b,f,2), ...]

간선 선택 (라인 3-9):

(b,c) 선택: 사이클이 없으므로 T에 추가.

(c,f) 선택: 사이클이 없으므로 T에 추가.

(b,f) 선택: T에 추가하면 b-c-f-b 사이클이 생기므로 버립니다 (라인 8).

(a,d) 선택: 사이클 없으므로 추가.

이 과정을 n-1개의 간선이 선택될 때까지 반복합니다.


#### 2. 시간 복잡도 유도
<br>
간선 정렬 (라인 1): 간선의 개수가 $m$일 때, 정렬에 $O(m \log m)$ 시간이 걸립니다.
<br>
사이클 검사 (라인 5): `while` 루프는 최대 $m$번 반복됩니다. 각 반복에서 사이클 검사가 필요합니다. Union-Find 자료구조를 사용하면 사이클 검사와 간선 추가(Union)에 거의 상수 시간($O(\alpha(n))$, $\alpha$는 아커만 함수의 역함수로 매우 작은 상수)이 걸립니다.

따라서, 전체 시간 복잡도는 간선 정렬 시간이 지배적이므로 <b>$O(m \log m)</b> 입니다.

---
### 프림 알고리즘 (Prim's Algorithm)

---

#### 1. 실습 과정 및 의사코드 연관 설명
<b>'하나의 정점에서 시작하여, 현재 트리에 연결된 간선 중 가장 가중치가 낮은 것을 선택하여 트리를 확장'</b>하는 전략입니다.

```pseudocode
PrimMST(G, s)
    시작점 s 선택, D[s] = 0
    for (모든 정점 v) { D[v] = ∞ }
    T = {s}
    while (T의 점 개수 < n) {
        T에 속하지 않은 점 중 D[v]가 최소인 점 v_min을 선택
        v_min을 T에 추가
        for (v_min에 인접한 모든 점 w) {
            if (간선 (v_min, w) 가중치 < D[w]) {
                D[w] = 간선 (v_min, w) 가중치 // 간선 완화
            }
        }
    }
```
강의 자료 29페이지의 예제(시작점 'c')를 봅시다.

초기화 (라인 1-3): D[c]=0, 나머지 D값은 ∞로 설정. T={c}.

첫 번째 확장 (라인 4-11):

T에 없는 점 중 D값이 최소인 점은 D[b]=1과 D[f]=1인 b 또는 f입니다. b를 선택했다고 가정합니다. v_min = b.

b를 T에 추가. T={c, b}.

b에 인접한 점들(a, d, f)에 대해 D값을 갱신(간선 완화)합니다. D[a]=∞ -> 3, D[d]=∞ -> 4, D[f]=1 (갱신 안됨).

이 과정을 n개의 점이 모두 T에 포함될 때까지 반복합니다.


#### 2. 시간 복잡도 유도
<br>
`while` 루프: $n-1$번 반복합니다.
<br>
최소값 찾기 (라인 5): 배열을 사용하여 D값 중 최솟값을 찾으려면 <b>$O(n)$</b>이 걸립니다.
<br>
갱신 (라인 7-11): 한 정점에 연결된 모든 간선을 확인하므로, 인접 리스트의 경우 해당 정점의 차수(degree)만큼, 인접 행렬의 경우 $O(n)$이 걸립니다.

배열 기반 구현의 경우, 총 시간 복잡도는 $(n-1) \times O(n) = O(n^2)$ 입니다. (우선순위 큐를 사용하면 <b>$O(m \log n)$</b>으로 개선 가능합니다.)

## 4.3 최단 경로 찾기 (Dijkstra's Algorithm)
하나의 출발점에서 다른 모든 정점까지의 최단 경로를 찾는 알고리즘입니다. 프림 알고리즘과 매우 유사한 구조를 가집니다.
---

### 1. 실습 과정 및 의사코드 연관 설명
<b>'출발점으로부터의 최단 거리가 확정되지 않은 점들 중, 거리가 가장 짧은 점을 선택하고, 그 점을 경유지로 삼아 인접한 다른 점들까지의 거리를 갱신(간선 완화)'</b>하는 전략입니다.

```pseudocode
ShortestPath(G, s)
    D 배열을 ∞로 초기화, D[s] = 0
    while (최단 거리가 확정되지 않은 점이 있으면) {
        확정되지 않은 점 중 D[v]가 최소인 점 v_min 선택
        v_min의 최단 거리 확정
        for (v_min에 인접한 모든 점 w) { // 간선 완화
            if (D[v_min] + (v_min,w) 가중치 < D[w]) {
                D[w] = D[v_min] + (v_min,w) 가중치
            }
        }
    }
```
강의 자료 45페이지 예제(출발점 '서울')를 봅시다.

초기화: D[서울]=0, 나머지 D값은 ∞.

1단계:

v_min = '서울'.

'서울'의 거리 확정.

간선 완화: D[천안]=12, D[원주]=15로 갱신.

2단계:

확정되지 않은 점(천안, 원주, ...) 중 D값이 가장 작은 '천안'(D=12)을 v_min으로 선택.

'천안'의 거리 12 확정.

간선 완화: D[논산] = D[천안]+4 = 16, D[대전] = D[천안]+10 = 22로 갱신.

이 과정을 모든 점의 최단 거리가 확정될 때까지 반복합니다.

---

### 2. 시간 복잡도 유도
다익스트라 알고리즘의 시간 복잡도 분석은 프림 알고리즘과 거의 동일합니다.
<br>
`while` 루프는 $n$번 실행됩니다.
<br>
`while` 루프 내에서 최소 거리를 가진 정점을 찾는 데 배열을 사용하면 $O(n)$이 걸립니다.

따라서 배열 기반 구현의 시간 복잡도는 <b>$O(n^2)$</b> 입니다.

## 4.4 부분 배낭 문제 (Fractional Knapsack)
0-1 배낭 문제와 달리, 물건을 쪼개서 담을 수 있습니다. 이 특징 덕분에 그리디 알고리즘으로 최적해를 구할 수 있습니다.
---

### 1. 실습 과정 및 의사코드 연관 설명
핵심 전략은 **'단위 무게 당 가치가 가장 높은 물건부터 욕심내어 담는 것'**입니다. 

```pseudocode
FractionalKnapsack(Items, C)
    각 물건의 '단위 무게 당 가치' 계산
    '단위 무게 당 가치'가 높은 순으로 물건들을 정렬 (S)
    w = 0, v = 0 // 현재 무게와 가치
    for each item x in S {
        if (w + x.weight <= C) { // 통째로 담을 수 있으면
            담는다; w += x.weight; v += x.value
        } else { // 부분적으로만 담을 수 있으면
            fraction = (C - w) / x.weight
            담는다 (fraction 만큼); v += x.value * fraction
            break // 배낭이 꽉 참
        }
    }
    return v
```
강의 자료 69페이지 예제(배낭 용량 40g)를 봅시다.

준비 (라인 1-2): 단위 그램당 가치를 계산하고 정렬합니다. S = [백금(6), 금(5), 은(0.4), 주석(0.1)]

담기 (라인 4-11):

백금(10g): 통째로 담습니다. w=10, v=60.

금(15g): 통째로 담습니다. w=10+15=25, v=60+75=135.

은(25g): 통째로 담을 수 없습니다(25+25 > 40). 남은 용량 40-25=15g 만큼만 부분적으로 담습니다 (라인 8-9). v = 135 + (10만원 * 15/25) = 141만원. 배낭이 꽉 차서 break.

---

### 2. 시간 복잡도 유도
단위 가치 계산 (라인 1): n개의 물건에 대해 한 번씩 계산하므로 O(n).
<br>
정렬 (라인 2): $n$개의 물건을 정렬하므로 $O(n \log n)$입니다.
<br>
배낭 채우기 (라인 4-11): 정렬된 물건 리스트를 한 번 순회하므로 $O(n)$입니다.

전체 시간 복잡도는 가장 오래 걸리는 정렬 과정에 의해 결정됩니다. 따라서 <b>$O(n \log n)$</b> 입니다.

## 4.5 집합 커버 문제 (Set Cover)
주어진 전체 집합 U를 가장 적은 수의 부분 집합들(집합 F에 속한)의 합집합으로 덮는(cover) 문제입니다. 그리디 전략은 최적해를 보장하지는 않지만, 효과적인 근사해를 찾아줍니다.
---

### 1. 실습 과정 및 의사코드 연관 설명
핵심 전략은 **'아직 커버되지 않은 원소를 가장 많이 포함하는 부분 집합을 욕심내어 선택하는 것'**입니다. 강의 자료 77페이지의 신도시 학교 배치 예제를 통해 과정을 살펴보겠습니다.

```pseudocode
SetCover(U, F)
    // 입력: 전체 집합 U, 부분 집합들의 집합 F
    // 출력: 집합 커버 C
    C = ∅
    while (U ≠ ∅) {
        U의 원소를 가장 많이 가진 집합 Si를 F에서 선택
        U = U - Si // U에서 Si의 원소들을 제거
        Si를 F에서 제거하고, Si를 C에 추가
    }
    return C
```
초기 상태: U = {1, 2, ..., 10}, C = ∅.

첫 번째 반복 (라인 2-6):

(라인 3) 아직 커버되지 않은 원소(U 전체)를 가장 많이 포함하는 집합을 찾습니다. S₄ = {2,3,4,5,7,8}가 6개로 가장 많으므로 선택됩니다.


(라인 4, 5) S₄를 C에 추가하여 C = {S₄}가 되고, U는 U - S₄ = {1, 6, 9, 10}으로 갱신됩니다.


두 번째 반복 (라인 2-6):


(라인 3) 현재 U = {1, 6, 9, 10}을 가장 많이 커버하는 집합은 S₆ = {5,6,7,9,10}입니다 (3개 원소 커버).


(라인 4, 5) S₆을 C에 추가하여 C = {S₄, S₆}가 되고, U는 U - S₆ = {1}로 갱신됩니다.


세 번째 반복 (라인 2-6):


(라인 3) 현재 U = {1}을 커버하는 집합 중 하나인 S₁을 선택합니다.


(라인 4, 5) S₁을 C에 추가하여 C = {S₄, S₆, S₁}이 되고, U는 U - S₁ = ∅이 됩니다.



종료: U가 공집합이 되었으므로 while 루프가 종료되고, 근사해로 C = {S₁, S₄, S₆}이 반환됩니다.

---

### 2. 시간 복잡도 유도
while 루프 (라인 2): 최악의 경우, 한 번에 하나의 원소만 커버된다면 루프는 U의 전체 원소 수(n)만큼 반복합니다. 따라서 루프는 최대 O(n)회 실행됩니다.
<br> 
최적의 집합 찾기 (라인 3): 루프 내부에서 가장 시간이 많이 걸리는 부분입니다.
<br> 
F에 남아있는 모든 부분 집합(최대 n개라 가정)을 순회해야 합니다.
<br> 
각 부분 집합 Si가 현재 U의 원소를 몇 개나 포함하는지 확인하려면, 두 집합을 비교해야 하며 이는 O(n) 시간이 걸릴 수 있습니다.
<br> 
따라서 라인 3의 연산은 $O(n) \times O(n) = O(n^2)$ 입니다.
<br> 
총 시간 복잡도: `while` 루프 횟수 $O(n)$과 루프 내부의 연산 $O(n^2)$를 곱하면, 전체 시간 복잡도는 <b>$O(n^3)</b>이 됩니다.

## 4.6 작업 스케줄링 (Job Scheduling)
여러 작업의 시작 시간과 종료 시간이 주어졌을 때, 최소한의 기계(강의실)를 사용하여 모든 작업을 수행하는 문제입니다.
---

### 1. 실습 과정 및 의사코드 연관 설명
그리디 전략은 <b>'가장 시작 시간이 빠른 작업부터 차례대로, 현재 작업을 수행할 수 있는 기계 중 가장 먼저 끝나는 기계에 배정'</b>하는 것입니다. 만약 가능한 기계가 없다면 새로운 기계를 할당합니다.

```pseudocode
JobScheduling(T) // T: 작업 리스트
    시작 시간으로 작업 리스트 L을 정렬한다.
    while (L ≠ ∅) {
        L에서 가장 이른 시작 시간 작업 ti를 가져온다.
        if (ti를 수행할 수 있는 기존 기계가 있으면) {
            ti를 해당 기계에 배정한다.
        } else {
            새 기계에 ti를 배정한다.
        }
        ti를 L에서 제거한다.
    }
```
강의 자료 92페이지의 예제를 봅시다.

정렬 (라인 1): 작업을 시작 시간 순으로 정렬합니다. L = {[0,2], [1,5], [1,6], [3,7], [5,9], [6,8], [7,8]} (강의 자료 순서에 맞춰 [1,5]를 먼저 배치).

스케줄링 (라인 2-9):

[0,2] -> 새 기계 1에 배정. (Machine 1 종료 시간: 2)

[1,5] -> 기계 1은 2시까지 사용 중이므로 배정 불가. 새 기계 2에 배정. (Machine 2 종료 시간: 5)

[1,6] -> 기계 1, 2 모두 사용 중. 새 기계 3에 배정. (Machine 3 종료 시간: 6)

[3,7] -> 기계 1은 2시에 끝나므로 배정 가능 (2 < 3). 기계 1에 배정. (Machine 1 종료 시간: 7)

[5,9] -> 기계 1(7시), 2(5시), 3(6시). 기계 2는 5시에 끝나므로 배정 가능. 기계 2에 배정. (Machine 2 종료 시간: 9)
... 이 과정을 모든 작업이 배정될 때까지 반복합니다.

---

### 2. 시간 복잡도 유도
<br>
정렬 (라인 1): $n$개의 작업을 시작 시간 기준으로 정렬하는 데 $O(n \log n)$ 시간이 걸립니다.
<br>
`while` 루프 (라인 2): $n$개의 모든 작업을 처리해야 하므로 $n$번 반복합니다.
<br>
기계 배정 (라인 4-7): 루프 내부에서 현재 작업 $t_i$를 배정할 기계를 찾아야 합니다. 사용 중인 기계가 $m$개일 때, 각 기계의 종료 시간을 모두 확인해야 하므로 $O(m)$ 시간이 걸립니다. 최악의 경우 모든 작업이 다른 기계에 배정되어 $m$은 $n$에 가까워질 수 있습니다.

따라서 루프 부분의 시간 복잡도는 $n \times O(m) = O(nm)$ 입니다.

전체 시간 복잡도는 정렬 시간과 루프 시간을 합한 <b>$O(n \log n + nm)$</b>이 됩니다.

## 4.7 허프만 압축 (Huffman Coding)
파일 압축을 위한 알고리즘으로, 파일에 자주 등장하는 문자에는 짧은 코드를, 드물게 등장하는 문자에는 긴 코드를 할당하여 전체 파일 크기를 줄이는 그리디 방식입니다.
---

### 1. 실습 과정 및 의사코드 연관 설명
핵심 전략은 <b>'가장 빈도수가 낮은 두 문자를 하나의 노드로 묶는 과정을 반복하여 이진 트리(허프만 트리)를 만드는 것'</b>입니다.

```pseudocode
HuffmanCoding(Frequencies)
    각 문자에 대한 노드 생성
    n개 노드를 빈도수에 대한 우선순위 큐(Q)에 넣는다.
    while (Q에 있는 노드 수 >= 2) {
        빈도수가 가장 적은 2개의 노드 (A, B)를 Q에서 제거 // Greedy Choice
        새 노드 N을 만들고, A와 B를 자식으로 연결
        N의 빈도수 = A의 빈도수 + B의 빈도수
        노드 N을 Q에 삽입
    }
    return Q에 남은 하나의 노드 (트리의 루트)
```
강의 자료 103페이지의 예제 (A:450, T:90, G:120, C:270)를 봅시다.

초기화 (라인 1-2): 우선순위 큐 Q에 [T:90, G:120, C:270, A:450]이 들어갑니다.

1단계 (라인 3-7):

(라인 4) 가장 빈도가 낮은 T(90)와 G(120)를 Q에서 제거합니다.

(라인 5-7) 두 노드를 자식으로 하는 새 부모 노드(빈도 90+120=210)를 만들어 Q에 삽입합니다. Q는 이제 [Node:210, C:270, A:450]가 됩니다.

2단계 (라인 3-7):

(라인 4) 가장 빈도가 낮은 Node(210)와 C(270)를 제거합니다.

(라인 5-7) 새 부모 노드(빈도 210+270=480)를 만들어 Q에 삽입합니다. Q는 [A:450, Node:480]가 됩니다.

3단계 (라인 3-7):


(라인 4-7) A(450)와 Node(480)를 제거하고, 최종 루트 노드(빈도 450+480=930)를 만들어 Q에 삽입합니다.

종료: Q에 노드가 하나만 남아 while 루프가 종료되고, 최종 트리가 완성됩니다. 이 트리에서 왼쪽 가지를 0, 오른쪽 가지를 1로 하여 각 문자의 코드를 얻습니다.

---

### 2. 시간 복잡도 유도
<br>
우선순위 큐 생성 (라인 2): $n$개의 문자로 이진 힙(우선순위 큐)을 구성하는 데는 $O(n)$ 시간이 걸립니다.
<br>
`while` 루프 (라인 3): 이 루프는 Q에 노드가 하나 남을 때까지 실행됩니다. 매 반복마다 노드 2개를 제거하고 1개를 삽입하므로 총 $n-1$번 반복됩니다.

루프 내부 연산 (라인 4, 7):
<br>
우선순위 큐에서 최소값 제거(Extract-Min) 연산은 $O(\log n)$ 시간이 걸립니다. 이를 두 번 수행합니다.
<br>
우선순위 큐에 새 노드 삽입(Insert) 연산은 $O(\log n)$ 시간이 걸립니다.

따라서 루프 한 번당 $O(\log n)$의 시간이 소요됩니다.

총 시간 복잡도는 $O(n) + (n-1) \times O(\log n)$ 이므로, 최종적으로 <b>$O(n \log n)</b>이 됩니다.

---

## Chapter 5: 동적 계획 알고리즘 (Dynamic Programming Algorithm) 

동적 계획법은 큰 문제를 작은 문제로 나누어 푼다는 점에서 분할 정복과 비슷하지만, 중복되는 계산을 피하기 위해 작은 문제들의 답을 저장해두고 재활용하는 점이 핵심입니다. 복잡한 최적화 문제를 해결하는 데 매우 유용합니다.

* 5.1 모든 쌍 최단 경로 (All Pairs Shortest Paths)
* 5.2 연속 행렬 곱셈 (Chained Matrix Multiplication)
* 5.3 편집 거리 문제 (Edit Distance)
* 5.4 배낭 문제 (Knapsack Problem)
* 5.5 동전 거스름돈 (Coin Change)

---

## 5.1 모든 쌍 최단 경로 (All-Pairs Shortest Paths) - 플로이드-워셜 알고리즘
이 알고리즘은 그래프의 모든 정점 쌍(i에서 j로 가는) 사이의 최단 경로를 한 번에 찾는 강력한 방법입니다.
---

### 1. 실습 과정 및 의사코드 연관 설명
플로이드 알고리즘의 핵심 아이디어는 <b>'거쳐갈 수 있는 정점(경유지)을 하나씩 늘려가면서 최단 경로를 점진적으로 갱신'</b>하는 것입니다.

```pseudocode
AllPairsShortest(D)
    // 입력: D[i,j] = 간선 (i,j)의 가중치
    // 출력: 모든 쌍 최단 경로 거리를 저장한 D
    for k = 1 to n // 경유할 정점 k
        for i = 1 to n // 출발 정점 i
            for j = 1 to n // 도착 정점 j
                D[i,j] = min( D[i,j], D[i,k] + D[k,j] )
```
강의 자료 17페이지의 그래프 예제를 통해 k=1일 때의 과정을 살펴보겠습니다.

초기 상태: D 테이블(D^0)은 각 정점 간의 직접 연결된 간선의 가중치로 초기화됩니다. 연결이 없으면 ∞입니다.

k=1 단계 (경유지로 1번 정점만 허용):

for 루프가 k=1로 시작됩니다. 이제 모든 정점 쌍 (i,j)에 대해, i에서 j로 바로 가는 경로와 i -> 1 -> j로 가는 경로 중 더 짧은 것을 선택합니다.

예를 들어, i=4, j=3일 때를 봅시다. 의사코드 4번 라인이 실행됩니다.

D[4,3]: 기존 경로는 없으므로 ∞ 입니다.

D[4,1] + D[1,3]: 4 -> 1의 거리는 -2, 1 -> 3의 거리는 2입니다. 따라서 -2 + 2 = 0 입니다.

min(∞, 0): 0이 더 작으므로 D[4,3]의 값은 0으로 갱신됩니다.

이 과정을 모든 (i,j) 쌍에 대해 반복합니다. k가 n까지 증가하면서, 모든 정점을 경유지로 고려하게 되어 최종적으로 모든 쌍의 최단 경로를 구하게 됩니다.

---

### 2. 시간 복잡도 유도
의사코드를 보면 명확하게 3개의 for 루프가 중첩되어 있습니다.

<br>
가장 바깥 $k$ 루프: 1부터 $n$까지 $n$번 반복합니다.
<br>
중간 $i$ 루프: 1부터 $n$까지 $n$번 반복합니다.
<br>
가장 안쪽 $j$ 루프: 1부터 $n$까지 $n$번 반복합니다.
<br>
가장 안쪽의 연산인 `min(D[i,j], D[i,k] + D[k,j])`는 덧셈 한 번과 비교 한 번으로, 상수 시간 $O(1)$이 걸립니다.

따라서 총 수행 시간은 $n \times n \times n = n^3$ 에 비례합니다.
<br>
최종 시간 복잡도는 <b>$O(n^3)$</b> 입니다.

## 5.2 연속 행렬 곱셈 (Chained Matrix Multiplication)
여러 행렬을 연속으로 곱할 때, 곱셈 순서에 따라 총 연산 횟수가 달라집니다. 이 알고리즘은 최소의 원소 곱셈 횟수를 찾는 문제입니다.
---

### 1. 실습 과정 및 의사코드 연관 설명
핵심 아이디어는 <b>'곱셈 체인의 길이(L)를 점차 늘려가며 최적의 곱셈 횟수를 테이블에 저장'</b>하는 것입니다. C[i,j]는 행렬 A 
i
 ​$A_i$
 부터 A 
j
 ​$A_j$
 까지 곱하는 데 필요한 최소 곱셈 횟수를 의미합니다.

```pseudocode
// 입력: 행렬 크기 d_0, d_1, ..., d_n
// 출력: C[1,n]
for i = 1 to n: C[i,i] = 0 // 길이가 1인 체인(행렬 1개)의 곱셈 횟수는 0
for L = 1 to n-1 // L: 곱셈 체인의 길이 (2부터 n까지)
    for i = 1 to n-L
        j = i + L
        C[i,j] = ∞
        for k = i to j-1 // 괄호를 칠 수 있는 모든 위치 k
            temp = C[i,k] + C[k+1,j] + d_{i-1} * d_k * d_j
            if (temp < C[i,j]): C[i,j] = temp
return C[1,n]
```
강의 자료 37페이지의 4개 행렬 예제를 봅시다.


L=1 (길이 2인 체인): A1xA2, A2xA3, A3xA4의 곱셈 횟수를 계산하여 C[1,2], C[2,3], C[3,4]를 채웁니다.

L=2 (길이 3인 체인):

C[1,3] ($A_1 \times A_2 \times A_3$)을 계산할 차례입니다. k루프(라인 6)가 k=1과 k=2 두 경우를 모두 시도합니다.

k=1: $(A_1) \times (A_2 \times A_3)$의 경우. 곱셈 횟수는 $C[1,1] + C[2,3] + d_0 \times d_1 \times d_3$ 입니다. C[1,1]과 C[2,3]은 이미 이전 단계에서 계산해 두었으므로 가져다 쓰기만 하면 됩니다.

k=2: $(A_1 \times A_2) \times (A_3)$의 경우. 곱셈 횟수는 $C[1,2] + C[3,3] + d_0 \times d_2 \times d_3$ 입니다.

두 결과 중 더 작은 값을 C[1,3]에 저장합니다. 이처럼 이전에 계산된 부분 문제의 해(C[1,2], C[2,3] 등)를 재사용하는 것이 DP의 핵심입니다.

---

### 2. 시간 복잡도 유도
알고리즘은 3개의 중첩된 for 루프로 구성되어 있습니다.
<br>
L 루프: 1부터 $n-1$까지 약 $n$번 반복합니다.
<br>
i 루프: 1부터 $n-L$까지 약 $n$번 반복합니다.
<br>
k 루프: $i$부터 $j-1$까지, 즉 $L$번 반복하므로 약 $n$번 반복합니다.
<br>
안쪽의 temp 계산은 상수 시간이므로 $O(1)$입니다.

따라서 전체 시간 복잡도는 약 $n \times n \times n$에 비례하여 <b>$O(n^3)$</b> 이 됩니다.

## 5.3 편집 거리 (Edit Distance)
두 문자열이 얼마나 다른지를 측정하는 방법으로, 한 문자열을 다른 문자열로 바꾸는 데 필요한 최소 연산(삽입, 삭제, 대체)의 수를 구합니다.
---

### 1. 실습 과정 및 의사코드 연관 설명
E[i,j]를 '문자열 S의 첫 i글자를 문자열 T의 첫 j글자로 바꾸는 데 필요한 최소 편집 거리'로 정의합니다.

```pseudocode
EditDistance(S, T, m, n)
    for i = 0 to m: E[i,0] = i // S를 빈 문자열로 바꾸려면 i번 삭제
    for j = 0 to n: E[0,j] = j // 빈 문자열을 T로 바꾸려면 j번 삽입
    for i = 1 to m
        for j = 1 to n
            alpha = (S[i] == T[j]) ? 0 : 1 // 문자가 같으면 비용 0, 다르면 1
            E[i,j] = min( E[i-1,j] + 1,       // 삭제(Delete)
                          E[i,j-1] + 1,       // 삽입(Insert)
                          E[i-1,j-1] + alpha ) // 대체/일치(Substitute/Match)
    return E[m,n]
```
'strong'을 'stone'으로 바꾸는 과정을 예로 E[4,3] ('stro' -> 'sto')을 계산해 봅시다.

초기화: 0번 행과 0번 열은 각각 0부터 m, 0부터 n까지의 값으로 채워집니다. 이는 빈 문자열과의 편집 거리를 의미합니다.

E[4,3] 계산 (라인 6): E[4,3]의 값은 왼쪽, 위, 왼쪽 대각선 위, 세 칸의 값에 의존합니다.

삭제: 'stro'를 'st'로 만든 후 'o'를 삭제. 비용은 E[3,3] + 1 = 1 + 1 = 2.

삽입: 'str'을 'sto'로 만든 후 'o'를 삽입. 비용은 E[4,2] + 1 = 2 + 1 = 3.

대체/일치: 'str'을 'st'로 만든 후, S[4]인 'o'와 T[3]인 'o'를 비교. 두 문자가 같으므로 alpha=0. 비용은 E[3,2] + 0 = 1 + 0 = 1.

이 세 값 (2, 3, 1) 중 최솟값인 1이 E[4,3]의 값이 됩니다. 이 과정을 테이블 전체에 대해 반복합니다.

---

### 2. 시간 복잡도 유도
알고리즘은 크기가 m x n인 2차원 테이블 E를 채웁니다.
<br>
의사코드를 보면 $i$에 대한 `for` 루프(1~$m$)와 $j$에 대한 `for` 루프(1~$n$)가 중첩되어 있습니다.
각 셀 E[i,j]를 계산하는 데는 주변 3개 셀을 참조하는 상수 시간 $O(1)$이 걸립니다.
<br>
따라서 전체 테이블을 채우는 데 걸리는 시간은 $m \times n \times O(1)$ 입니다.

최종 시간 복잡도는 <b>$O(mn)$</b> 입니다.

## 5.4 0-1 배낭 문제 (0-1 Knapsack Problem)
각각 무게와 가치가 있는 물건들을, 용량이 정해진 배낭에 담아 가치의 합이 최대가 되도록 하는 문제입니다. 물건은 쪼갤 수 없습니다.
---

### 1. 실습 과정 및 의사코드 연관 설명

K[i, w]를 '물건 1부터 i까지 고려하고, 배낭의 임시 용량이 w일 때의 최대 가치'로 정의합니다.

```pseudocode
Knapsack(C, W, V, n)
    for i = 0 to n: K[i,0] = 0
    for w = 0 to C: K[0,w] = 0
    for i = 1 to n
        for w = 1 to C
            if (W[i] > w) // 물건 i가 너무 무거워서 못 담는 경우
                K[i,w] = K[i-1,w] // 물건 i를 안 담는 경우와 같음
            else // 물건 i를 담을지 말지 선택
                K[i,w] = max( K[i-1,w],            // 물건 i를 안 담을 때의 가치
                              V[i] + K[i-1, w-W[i]] ) // 물건 i를 담을 때의 가치
    return K[n,C]
```
강의 자료 67페이지 예제에서 K[2,9]를 계산하는 과정을 봅시다. (물건2: 무게 4, 가치 40)

i=2, w=9 입니다. W[2]=4는 w=9보다 작으므로 8번 라인이 실행됩니다.

K[i-1, w] (물건 2를 안 담는 경우): 물건 1만 고려하고 용량이 9일 때의 최대 가치, 즉 K[1,9]입니다. 표에서 이 값은 10입니다.

V[i] + K[i-1, w-W[i]] (물건 2를 담는 경우): 물건 2의 가치 40 + (물건 1만 고려하고 용량이 9-4=5일 때의 최대 가치 K[1,5]) 입니다. 표에서 K[1,5]는 10이므로, 이 경우의 가치는 40 + 10 = 50입니다.

max(10, 50): 두 경우 중 더 큰 값인 50이 K[2,9]의 값이 됩니다.

---

### 2. 시간 복잡도 유도
알고리즘은 n x C 크기의 2차원 테이블 K를 채웁니다.
<br>
의사코드의 $i$에 대한 `for` 루프는 $n$번, $w$에 대한 `for` 루프는 $C$번 반복합니다.
<br>
각 셀 K[i,w]를 계산하는 데는 `max` 함수와 덧셈 등 상수 시간 $O(1)$이 걸립니다.

따라서 총 시간 복잡도는 $n \times C \times O(1)$ 입니다.

최종 시간 복잡도는 <b>$O(nC)$</b> 입니다.

## 5.5 동전 거스름돈 (Coin Change)
그리디 알고리즘으로 최적해를 구하지 못하는 경우에도, 동적 계획법을 사용하면 항상 최소 동전 개수를 찾을 수 있습니다.
---

### 1. 실습 과정 및 의사코드 연관 설명
C[j]를 '거스름돈 j원을 만드는 데 필요한 최소 동전 개수'로 정의합니다.

```pseudocode
DPCoinChange(n, d)
    // 입력: 거스름돈 n, 동전 종류 d1, ..., dk
    C[0] = 0
    for j = 1 to n // 1원부터 n원까지 거스름돈 j를 계산
        C[j] = ∞
        for i = 1 to k // 모든 동전 종류를 시도
            if (d[i] <= j) and (C[j-d[i]] + 1 < C[j])
                C[j] = C[j-d[i]] + 1
    return C[n]
```
거스름돈 n=20원, 동전 [1, 5, 10, 16]이 주어졌을 때 C[20]을 계산해 봅시다.

j=20일 때, 4번 for 루프가 돌면서 모든 동전을 사용해 보는 경우를 고려합니다.

1원 동전 사용: 비용은 C[19] + 1. 이전 계산에서 C[19]=4이므로, 비용은 5. C[20]는 5로 업데이트.

5원 동전 사용: 비용은 C[15] + 1. 이전 계산에서 C[15]=2이므로, 비용은 3. min(5, 3) = 3. C[20]는 3으로 업데이트.

10원 동전 사용: 비용은 C[10] + 1. 이전 계산에서 C[10]=1이므로, 비용은 2. min(3, 2) = 2. C[20]는 2로 업데이트.

16원 동전 사용: 비용은 C[4] + 1. 이전 계산에서 C[4]=4이므로, 비용은 5. min(2, 5) = 2. C[20]는 2로 유지.

모든 동전을 시도한 후 C[20]의 최종 값은 2가 됩니다. 이는 그리디 알고리즘이 찾은 5개(16+1+1+1+1)보다 최적의 해입니다.

2. 시간 복잡도 유도
알고리즘은 크기 n인 1차원 배열 C를 채웁니다.

바깥 $j$ 루프는 1부터 $n$까지 $n$번 반복합니다.

안쪽 $i$ 루프는 동전의 종류 수 $k$만큼 반복합니다.

안쪽의 `if`문은 상수 시간 $O(1)$이 걸립니다.

따라서 총 수행 시간은 $n \times k \times O(1)$ 입니다.

최종 시간 복잡도는 <b>$O(nk)$</b> 입니다.
