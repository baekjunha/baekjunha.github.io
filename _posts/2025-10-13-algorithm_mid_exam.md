---
title: "알고리즘 핵심: 시간 복잡도 유도 과정 완벽 정복 (분할 정복, 그리디, DP)"
categories: algorithm
tags: [algorithm, time-complexity, divide-and-conquer, greedy, dynamic-programming]
toc: true
toc_sticky: true
author_profile: false
use_math: true
---

이 문서는 교재 3장부터 5장까지 주요 알고리즘의 시간 복잡도 유도 과정을 중심으로 상세히 설명합니다. 각 알고리즘의 핵심 아이디어부터 의사코드(pseudo code) 분석, 그리고 시간 복잡도가 어떻게 도출되는지 단계별로 학습합니다.

-----

## Chapter 3: 분할 정복 알고리즘 (Divide and Conquer)

**분할 정복**은 이름 그대로, 큰 문제를 해결하기 어려운 작은 문제로 **'분할(Divide)'하고, 각각의 작은 문제를 해결('정복, Conquer'**)한 뒤, 그 결과들을 \*\*'조합(Combine)'\*\*하여 원래 문제의 답을 얻는 강력한 알고리즘 설계 기법입니다. 마치 큰 퍼즐을 여러 조각으로 나눠 맞춘 뒤 합치는 것과 비슷하죠.

### 3.1 합병 정렬 (Merge Sort)

**학습 목표:**

  * 합병 정렬의 '분할-정복-조합' 과정을 이해합니다.
  * 합병 정렬의 시간 복잡도 재귀식을 세우고, $O(n \log n)$이 도출되는 과정을 설명할 수 있습니다.

**핵심 아이디어:**
정렬할 배열을 더 이상 나눌 수 없을 때까지(원소가 하나만 남을 때까지) 절반으로 계속 나눕니다. 그리고 나눠진 작은 배열부터 \*\*'합병(Merge)'\*\*하면서 정렬을 완성해 나갑니다. [cite\_start]여기서 핵심은 **두 개의 이미 정렬된 배열을 합치는 작업은 매우 빠르다**는 점입니다. [cite: 2022, 2023]
여기서 핵심은 **두 개의 이미 정렬된 배열을 합치는 작업은 매우 빠르다**는 점입니다.

#### **시간 복잡도 유도 과정 ($O(n \log n)$)**

1.  **재귀식 세우기 (Recurrence Relation)**
    크기가 $n$인 배열을 정렬하는 데 걸리는 시간을 $T(n)$이라고 합시다.

      * **분할 (Divide):** 배열을 절반으로 나누는 것은 단순히 중간 인덱스를 계산하는 것이므로 $O(1)$의 시간이 걸립니다.
      * **정복 (Conquer):** 크기가 $n/2$인 두 개의 부분 배열을 재귀적으로 정렬하므로, $2 \times T(n/2)$의 시간이 필요합니다.
      * **조합 (Combine):** 정렬된 두 개의 $n/2$ 크기 배열을 하나의 $n$ 크기 배열로 합병하는 데는 $O(n)$의 시간이 걸립니다.

    이를 종합하면 다음과 같은 재귀식을 세울 수 있습니다.
    $$T(n) = 2T(n/2) + O(n)$$

2.  **재귀 트리(Recursion Tree)를 이용한 도식화**
    위 재귀식을 트리 형태로 시각화하면 각 단계(level)에서 필요한 연산량을 쉽게 파악할 수 있습니다.

| 레벨 (Level) | 문제 크기 | 문제 개수 | 각 문제의 조합 비용 | 레벨 총비용 |
| :--- | :--- | :--- | :--- | :--- |
| 0 | $n$ | 1 ($n$) | $cn$ | $cn$ |
| 1 | $n/2$ | 2 ($n/2, n/2$) | $cn/2$ | $2 \times (cn/2) = cn$ |
| 2 | $n/4$ | 4 ($n/4, ...$) | $cn/4$ | $4 \times (cn/4) = cn$ |
| ... | ... | ... | ... | ... |
| $k-1$ | $n/2^{k-1}$ | $2^{k-1}$ | $cn/2^{k-1}$ | $2^{k-1} \times (cn/2^{k-1}) = cn$ |
| $k$ (마지막) | 1 | $n$ | $O(1)$ | $O(n)$ |

  * **트리의 높이 (Height):** 문제가 크기 1이 될 때까지 분할됩니다. $n/2^k = 1$ 이 되는 $k$를 찾으면, $k = \log_2 n$ 입니다. [cite\_start]즉, 트리의 높이는 약 $\log n$입니다. [cite: 2176]
  * 즉, 트리의 높이는 약 $\log n$입니다.
  * **각 레벨의 총비용:** 각 레벨에서 합병에 드는 총비용은 $O(n)$으로 동일합니다.

3.  **최종 시간 복잡도 계산**
    총 시간 복잡도는 \*\*(각 레벨의 비용) $\times$ (트리의 높이)\*\*로 계산할 수 있습니다.
    $$T(n) = O(n) \times \log n = O(n \log n)$$
    따라서 합병 정렬의 시간 복잡도는 \*\*$O(n \log n)$\*\*이 됩니다.

-----

### 3.2 퀵 정렬 (Quick Sort)

**학습 목표:**

  * 퀵 정렬의 '피봇(pivot)'을 중심으로 한 분할 과정을 이해합니다.
  * 최선, 평균, 최악의 경우에 따라 시간 복잡도가 달라지는 이유를 설명할 수 있습니다.

**핵심 아이디어:**
배열에서 기준이 되는 원소, 즉 \*\*피봇(pivot)\*\*을 하나 고릅니다. 그런 다음, 피봇보다 작은 원소들은 모두 피봇의 왼쪽으로, 큰 원소들은 모두 오른쪽으로 옮깁니다. 이 과정을 \*\*분할(Partition)\*\*이라고 합니다. 분할이 끝나면 피봇은 자기 자리를 찾게 되며, 이 과정을 왼쪽과 오른쪽 부분 배열에 대해 재귀적으로 반복합니다.

#### **시간 복잡도 유도 과정**

퀵 정렬의 시간 복잡도는 **피봇을 어떻게 선택하느냐**에 따라 크게 달라집니다.

1.  **최선/평균의 경우: $O(n \log n)$**

      * **가정:** 매번 분할할 때마다 배열이 거의 절반으로 나뉜다고 가정합니다. (예: 피봇으로 배열의 중앙값이 선택되는 경우)
      * **재귀식:** 크기 $n$인 배열을 분할하는 데는 모든 원소를 피봇과 비교해야 하므로 $O(n)$의 시간이 걸립니다. 이후 약 $n/2$ 크기의 두 부분 문제로 나뉘므로 재귀식은 합병 정렬과 동일합니다.
        $$T(n) = 2T(n/2) + O(n)$$
      * **결론:** 합병 정렬과 마찬가지로, 재귀 트리를 통해 분석하면 \*\*$O(n \log n)$\*\*의 시간 복잡도를 가집니다. 랜덤하게 피봇을 선택할 경우에도 평균적으로 이와 같은 성능을 기대할 수 있습니다.

2.  **최악의 경우: $O(n^2)$**

      * **가정:** 매번 분할할 때마다 배열이 한쪽으로 치우쳐서 나뉘는 경우입니다. (예: 이미 정렬된 배열에서 항상 첫 번째 원소를 선택하는 경우)
      * **재귀식:** 이 경우, 문제는 크기가 0인 부분 문제와 $n-1$인 부분 문제로 나뉩니다.
        $$T(n) = T(n-1) + O(n)$$
      * **유도 과정:**
        $T(n) = T(n-1) + cn$
        $= (T(n-2) + c(n-1)) + cn$
        $= T(n-2) + c(n-1 + n)$
        $= T(1) + c(2 + 3 + ... + n)$
        $= O(1) + c \sum_{i=2}^{n} i = c \left( \frac{n(n+1)}{2} - 1 \right)$
      * **결론:** 이는 등차수열의 합과 같으므로, \*\*$O(n^2)$\*\*의 시간 복잡도를 가집니다.

-----

### 3.3 선택 문제 (Selection Problem)

**학습 목표:**

  * 선택 문제의 정의를 이해하고, 퀵 정렬의 분할 아이디어를 어떻게 활용하는지 설명할 수 있습니다.
  * 선택 알고리즘의 평균 시간 복잡도가 $O(n)$인 이유를 직관적으로 이해합니다.

**핵심 아이디어:**
$n$개의 숫자 중에서 $k$번째로 작은 숫자를 찾는 문제입니다. 퀵 정렬의 분할(Partition) 과정을 그대로 활용합니다. 피봇을 정하고 분할을 수행하면, 피봇은 배열에서 $p$번째 위치에 자리 잡게 됩니다.

  * 만약 $p=k$이면, 피봇이 바로 우리가 찾던 $k$번째 숫자입니다.
  * 만약 $p>k$이면, $k$번째 숫자는 피봇의 왼쪽에 있으므로 왼쪽 부분 배열에서만 탐색을 계속합니다.
  * 만약 $p<k$이면, 오른쪽 부분 배열에서 $(k-p)$번째 숫자를 찾습니다.

#### **시간 복잡도 유도 과정 (평균 $O(n)$)**

1.  **재귀식 세우기**

      * **최악의 경우:** 퀵 정렬처럼 매번 한쪽으로 치우치면 $T(n) = T(n-1) + O(n)$이 되어 $O(n^2)$이 됩니다.
      * **평균적인 경우:** 피봇이 랜덤하게 선택될 때, 평균적으로 탐색 범위가 일정 비율로 줄어든다고 기대할 수 있습니다. 이상적으로 절반씩 줄어든다면,
        $$T(n) = T(n/2) + O(n)$$

2.  **재귀식 풀이**
    $T(n) = T(n/2) + cn$
    $= (T(n/4) + c(n/2)) + cn$
    $= T(n/8) + c(n/4) + c(n/2) + cn$
    $= cn(1 + 1/2 + 1/4 + ...)$
    등비급수의 합 $\sum_{i=0}^{\infty} (\frac{1}{2})^i = \frac{1}{1-1/2} = 2$ 이므로,
    $T(n) = 2cn = O(n)$

3.  **결론**
    매 단계에서 탐색 범위를 **한쪽만** 고려하면 되므로, 재귀 호출이 하나뿐입니다. 이로 인해 전체 연산량의 합이 $O(n)$에 수렴하게 됩니다. [cite\_start]따라서 선택 문제의 평균 시간 복잡도는 \*\*$O(n)$\*\*입니다. [cite: 2495]
    따라서 선택 문제의 평균 시간 복잡도는 \*\*$O(n)$\*\*입니다.

-----

## Chapter 4: 그리디 알고리즘 (Greedy Algorithm)

**그리디 알고리즘**은 '탐욕적인' 또는 '눈앞의 이익을 쫓는' 방식으로, 각 단계에서 **그 순간에 최적이라고 생각되는 선택**을 하는 기법입니다. 이러한 근시안적인 선택들이 모여 최종적으로 전체 문제의 최적해를 구하는 방식이죠. 모든 문제에 적용할 수는 없지만, 특정 조건(최적 부분 구조, 탐욕적 선택 속성)을 만족하는 문제에서는 매우 빠르고 효율적인 해법이 됩니다.

### 4.2 최소 신장 트리 (Minimum Spanning Tree, MST)

주어진 가중치 그래프에서 모든 정점을 사이클 없이 연결하되, 간선 가중치의 합이 최소가 되는 트리를 찾는 문제입니다.

#### **1. 크러스컬 알고리즘 (Kruskal's Algorithm)**

**핵심 아이디어:**
가장 '욕심나는' 간선, 즉 **가중치가 가장 작은 간선부터** 차례대로 선택합니다. 단, 간선을 추가했을 때 **사이클이 형성되면 그 간선은 건너뜁니다.** 이 과정을 간선을 $(n-1)$개 선택할 때까지 반복합니다.

**시간 복잡도 유도 과정 ($O(m \log m)$):**

  * **간선 정렬:** 모든 간선($m$개)을 가중치 순으로 정렬해야 합니다. 효율적인 정렬 알고리즘(힙 정렬, 합병 정렬 등)을 사용하면 **$O(m \log m)$** 또는 \*\*$O(m \log n)$\*\*이 걸립니다 (간선 수는 최대 $n^2$이므로 $\log m$은 $\log n^2 = 2\log n$ 과 유사).
  * **간선 선택 및 사이클 검사:** 정렬된 간선을 하나씩 확인하면서 ($m$번 반복), 사이클 생성 여부를 검사하고 트리에 추가합니다. 유니온-파인드(Union-Find) 자료구조를 사용하면 사이클 검사는 거의 $O(1)$에 가깝습니다.
  * **최종 시간 복잡도:** 전체 과정에서 가장 시간이 많이 소요되는 부분은 **간선 정렬**입니다. 따라서 크러스컬 알고리즘의 시간 복잡도는 \*\*$O(m \log m)$\*\*이 됩니다.

#### **2. 프림 알고리즘 (Prim's Algorithm)**

**핵심 아이디어:**
임의의 한 정점에서 시작합니다. 현재 트리에 포함된 정점들과 포함되지 않은 정점들을 연결하는 간선 중 **가장 가중치가 작은 간선**을 선택하여 트리를 확장해 나갑니다. 마치 하나의 트리가 점점 자라나는 모습과 같습니다.

**시간 복잡도 유도 과정 ($O(n^2)$ 또는 $O(m \log n)$):**

  * **기본 구현 (배열 사용):**
      * 총 $n-1$개의 간선을 선택해야 합니다.
      * 각 단계에서, 트리에 포함되지 않은 정점들 중 트리와 가장 가까운 정점을 찾기 위해 모든 정점까지의 거리를 확인해야 합니다 ($O(n)$).
      * 이를 $n-1$번 반복하므로 총 시간 복잡도는 \*\*$O(n^2)$\*\*이 됩니다.
  * **개선된 구현 (우선순위 큐/최소 힙 사용):**
      * 트리에 인접한 정점까지의 거리를 우선순위 큐에 저장합니다.
      * 다음으로 추가할 간선을 찾는 것은 큐에서 최솟값을 추출하는 것과 같으므로 $O(\log n)$이 걸립니다.
      * 새로운 정점이 추가될 때마다 인접한 정점들의 거리 값을 갱신(decrease-key)하는데, 이 또한 $O(\log n)$이 걸립니다. 모든 간선을 한 번씩 고려하므로, 총 시간 복잡도는 \*\*$O(m \log n)$\*\*이 됩니다.

-----

### 4.3 최단 경로 찾기: 다익스트라 알고리즘 (Dijkstra's Algorithm)

**핵심 아이디어:**
하나의 출발점(source)에서 다른 모든 정점까지의 최단 경로를 찾는 알고리즘입니다. 프림 알고리즘과 매우 유사합니다. 출발점으로부터의 **최단 거리가 확정된 정점들의 집합**을 넓혀나갑니다. [cite\_start]매 단계마다, 아직 확정되지 않은 정점들 중에서 출발점으로부터의 거리가 가장 짧은 것을 '욕심내어' 선택하고, 그 정점의 최단 거리를 확정합니다. [cite: 6825, 6826]
매 단계마다, 아직 확정되지 않은 정점들 중에서 출발점으로부터의 거리가 가장 짧은 것을 '욕심내어' 선택하고, 그 정점의 최단 거리를 확정합니다.

**시간 복잡도 유도 과정 ($O(n^2)$ 또는 $O(m \log n)$):**
다익스트라 알고리즘의 동작 방식과 시간 복잡도 분석은 프림 알고리즘과 거의 동일합니다.

  * **기본 구현 (배열 사용):** 다음으로 방문할 최단 거리의 정점을 찾기 위해 매번 배열 전체를 순회하므로 \*\*$O(n^2)$\*\*입니다.
  * **개선된 구현 (우선순위 큐/최소 힙 사용):** 마찬가지로 우선순위 큐를 사용하면 \*\*$O(m \log n)$\*\*으로 개선할 수 있습니다.

-----

## Chapter 5: 동적 계획법 (Dynamic Programming, DP)

**동적 계획법**은 큰 문제의 해답에 그보다 작은 문제들의 해답이 포함되어 있을 때 사용하는 강력한 기법입니다. 분할 정복과 비슷하지만, DP는 부분 문제들이 서로 \*\*'중복(Overlapping Subproblems)'\*\*된다는 특징이 있습니다. 따라서 한 번 계산한 부분 문제의 답을 \*\*'기억(Memoization)'\*\*해두고 재활용함으로써 불필요한 계산을 줄입니다. 보통 상향식(Bottom-up)으로 가장 작은 문제부터 테이블을 채워나가며 최종 해답을 구합니다.

### 5.1 모든 쌍 최단 경로: 플로이드-워셜 알고리즘 (Floyd-Warshall)

**핵심 아이디어:**
그래프의 모든 정점 쌍($i, j$) 사이의 최단 경로를 구하는 알고리즘입니다. "정점 $k$를 거쳐가는 경로가 기존 경로보다 짧은가?"를 모든 $k$와 모든 쌍 $(i, j)$에 대해 검사하며 최단 거리를 점진적으로 갱신합니다.

**시간 복잡도 유도 과정 ($O(n^3)$):**

  * **의사코드 구조:**
    ```
    for k from 1 to n:      // 거쳐갈 중간 노드
        for i from 1 to n:  // 출발 노드
            for j from 1 to n: // 도착 노드
                D[i,j] = min(D[i,j], D[i,k] + D[k,j])
    ```
  * **계산:** 3개의 중첩된 반복문이 각각 $n$번씩 실행됩니다. 내부 연산은 $O(1)$입니다.
  * **최종 시간 복잡도:** 따라서 총 시간 복잡도는 $n \times n \times n = \textbf{O(n³)}$입니다. 매우 직관적이죠.

### 5.2 연속 행렬 곱셈 (Chained Matrix Multiplication)

**핵심 아이디어:**
$A_1 \times A_2 \times ... \times A_n$과 같이 행렬이 연속으로 주어졌을 때, 곱셈 순서를 어떻게 정해야 총 곱셈 횟수가 최소가 되는지 찾는 문제입니다. DP를 이용해 부분 문제, 즉 "i번째부터 j번째 행렬까지의 최소 곱셈 횟수"를 테이블에 저장하며 최종 답을 구합니다.

**시간 복잡도 유도 과정 ($O(n^3)$):**

  * **부분 문제 정의:** $C[i, j]$를 $A_i$부터 $A_j$까지 곱하는 데 필요한 최소 곱셈 횟수라고 정의합니다.
  * **점화식:**
    $$C[i, j] = \min_{i \le k < j} \{ C[i, k] + C[k+1, j] + d_{i-1}d_k d_j \}$$
  * **의사코드 구조:**
    ```
    for L from 1 to n-1:       // 곱할 행렬의 개수 (부분 문제의 크기)
        for i from 1 to n-L:   // 시작 행렬 인덱스
            j = i + L          // 끝 행렬 인덱스
            for k from i to j-1: // 분할 지점
                // 점화식 계산
    ```
  * **계산:** 3개의 중첩된 반복문이 실행됩니다. 각 반복문의 범위가 조금씩 다르지만, 대략적으로 $n \times n \times n$에 비례하는 연산을 수행합니다.
  * **최종 시간 복잡도:** 따라서 총 시간 복잡도는 \*\*$O(n^3)$\*\*입니다.

### 5.4 0-1 배낭 문제 (0-1 Knapsack Problem)

**핵심 아이디어:**
각각 무게와 가치가 정해진 $n$개의 물건이 있을 때, 용량이 $C$인 배낭에 물건을 담아 가치의 합이 최대가 되도록 하는 문제입니다. 물건은 쪼갤 수 없습니다. DP 테이블 $K[i, w]$를 \*\*"물건 1부터 $i$까지만 고려하고, 배낭 용량이 $w$일 때의 최대 가치"\*\*로 정의합니다.

**시간 복잡도 유도 과정 ($O(nC)$):**

  * **점화식:** $i$번째 물건을 넣을지 말지 결정합니다.
      * 넣지 않는 경우: $K[i-1, w]$
      * 넣는 경우: $K[i-1, w - w_i] + v_i$
        이 둘 중 더 큰 값을 선택합니다.
  * **의사코드 구조:**
    ```
    for i from 1 to n:      // 각 물건에 대하여
        for w from 1 to C:  // 각 배낭 용량에 대하여
            // 점화식 계산 (O(1))
    ```
  * **계산:** 2개의 중첩된 반복문이 각각 $n$번, $C$번 실행됩니다.
  * **최종 시간 복잡도:** 총 시간 복잡도는 $n \times C = \textbf{O(nC)}$입니다. 이 알고리즘은 배낭의 용량 $C$가 매우 크면 효율적이지 않기 때문에 **유사 다항 시간(Pseudo-polynomial time)** 알고리즘이라고 부릅니다.